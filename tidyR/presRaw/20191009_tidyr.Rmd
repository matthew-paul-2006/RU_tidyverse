---
title: "Getting tidy <html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>"
author: "Rockefeller University, Bioinformatics Resource Centre"
date: "http://rockefelleruniversity.github.io/Intro_To_R_1Day/"
output: 
  xaringan::moon_reader:
    css: ["default", "metropolisCustom.css", "metropolis-fontsCustom.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
  html_document:
    toc: true # table of contents true
    toc_float: yes
    depth: 3  # upto three depths of headings (specified by #, ## and ###)
    number_sections: false  ## if you want number sections at each table header
    theme: united  # many options for theme, this one is my favorite.
    highlight: tango  # specifies the syntax highlighting style
params:
  isSlides: "no"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
AsSlides <- TRUE
library(org.Hs.eg.db)
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
```

---
# Data wrangling with Tidy

<b>Some problems we face when dealing with data regularly.</b>

<ul>
  <li>Every dataset is different. Sometimes very different.</li>
  <li>There are many ways to do things. Everyone has their favorite syntax.</li>
</ul>

<b>The issue:</b>
Many fundamental data processing functions exist in <i>Base R</i> and beyond. Sometimes they can be inconsistent or unnecessarily complex. Especially when dealing with non-standard dataframes. The result is code that is confusing and doesn't flow i.e. nested functions

---
## What does it mean to be tidy?

Tidyverse is most importantly a philosophy for data analysis that more often then not makes wrangling data easier. The tidyverse community have built what they describe as an <i>opinionated</i> group of packages. These packages readily talk to one another. 

<ul>
  <li>More efficient code</li>
  <li>Easier to remember syntax</li>
  <li>Easier to read syntax</li>
</ul>

You can read their <a href="https://cran.r-project.org/web/packages/tidyverse/vignettes/manifesto.html">manifesto</a> to get a better understanding of the tidy ethos. 
  
---
## What does it <i>actually</i> mean to be tidy?

<ul>
  <li>A defined vision for coding style in R  
  <li>A defined vision for data formats in R
  <li>A defined vision for package design in R
  <li>Unified set of community pushing in a cohesive direction
  <li>Critical mass of people to influence the way the whole R community evolves
</ul>

---
## What are the main tidy tools?

<ul>
  <li>ggplot2 – making pretty graphs 
  <li>readr – reading data into R  
  <li>dplyr – manipulating data  
  <li>tibble - working with tibbles  
  <li>tidyr – miscellaneous tools for tidying data
  <li>purrr - iterating over data  
  <li>stringr – working with strings  
  <li>forcats - working with factors  
</ul>

Other tools have now been made for the tidy community. This community also overlaps with bioconductor. But the packages above are the linchpins that hold it together. 

---
## What are we doing today

Workflow Image for working with data.

---
## What we won't be doing today

We already have a course online for plotting, including ggplot.     

https://rockefelleruniversity.github.io/Plotting_In_R/

---
# Lets get tidy!
First step lets load in the data we are using today
```{r}
cat(getwd())
load(file='dataset/my_tidy.Rdata')
```

---
## Are all data frames equal?
```{r}
head(df1)
```

```{r}
head(df2)
```

---
### Are all data frames equal?
```{r}
head(df3a)
```

```{r}
head(df3b)
```

---
## What is a tidy dataset?

A tidy dataset is a data frame (or table) for which the following are true:

* Each variable has its own column
* Each observation has its own row
* Each value has its own cell

***Which of our dataframes is tidy?***
--
<p>&nbsp;</p>
Our first dataframe is tidy

---
## Why bother?

Consistent dataframe layouts help to ensure that all values are present and that relationships between data points are clear.

R is a vectorized programming language. R builds data frames from vectors, and R works best when its operation are vectorized. Tidy data utilizes of both of these aspects of R.

=> Precise and Fast

---
## Lets load in the tidyverse
```{r}
library(tidyverse)
```

---
## These tools have same logic

 -> insert graphic here
 https://github.com/trinker/tidyr_in_a_nutshell

---
# dplyr
This package contains a variety of tools to access and manipulate dataframes.

---
## dplyr::select 
**Select** allows you to make a vector from a specific variable
```{r}
# Select one variable (common_name)
select(df1, common_name)
```

---
#### dplyr::select
**Select** allows you to make a dataframe from several variables
```{r}
# Select two variables (age_classbylength and common_name)
select(df1, age_classbylength, common_name)
```

---
#### dplyr::select
**Select** allows you to make a dataframe excluding a variable
```{r}
# Select all but one variable (length_mm)
select(df1,-length_mm)
```

---
#### dplyr::select
**Select** allows you to make a dataframe from a range of variables
```{r}
# Select all a range of contiguous varibles (common_name:length_mm)
select(df1, common_name:length_mm)
```

---
## dplyr::filter - (pt1)
__Filter__ allows you to access observations based on a criteria
```{r}
# Filter all observation where the variable common_name is Sockeye salmon
filter(df1, common_name == 'Sockeye salmon')
```

---
## dplyr::filter - (pt2)
__Filter__ allows you to access observations based on several criteria
```{r}
# Filter all observations where the variable common_name is either Sockeye salmon or Chinook Salmon
filter(df1, common_name %in% c('Sockeye salmon', 'Chinook salmon'))
```

---
## dplyr::filter - (pt3)
__Filter__ allows you to access observations based on specific strings
```{r}
# Filter all observations where the variable common_name ends with 'salmon'. To do this we use stringr function str_ends recognise strings that end with 'salmon'.
filter(df1, str_ends(common_name, 'salmon'))
```

---
## dplyr::filter - (pt4)
__Filter__ allows you to access observations based on operators
```{r}
# Filter all observations where the variable length_mm is greater than 200 or less than 120
filter(df1, length_mm > 200 | length_mm < 120)
```

---
## CHALLENGE
<p>&nbsp;</p>
_ Create a dataframe with the variables _age_ and _IGF_ for only the _Steelhead_ fish
_ Create a dataframe with all the variables except the _IGF_ values, for all fish that begin with _S_

---
## ANSWERS
```{r}
# Create a dataframe of the variables _age_ and _IGF_ of only the _Steelhead_ fish
df1_A <- filter(df1, common_name == 'Steelhead')
select(df1_A, age_classbylength, IGF1_ng_ml)

# Create a dataframe of all variables but the _IGF_ values, for all fish that begin with _S_
df1_A <- filter(df1, str_starts(common_name,'S'))
select(df1_A, -IGF1_ng_ml)
```

---
## dplyr::arrange - (pt1)
_Arrange_ sorts the dataframe based on a specific variable
```{r}
# Arrange the data based on the variable length_mm
arrange(df1, length_mm)
```
---
## dplyr::arrange - (pt2)
_Arrange_ sorts the dataframe based on specific variables
```{r}
# Arrange the data first based on the variable common_name, 
# then secondly based on length_mm in a descending order.
arrange(df1, common_name, desc(length_mm))
```

---
## dplyr::mutate - (pt1)
_Mutate_ creates a new variable based on some form of computation
```{r}
# A new variable is created based on the calculation of the
# z-score of the variable IGF1_ng_ml using scale()
mutate(df1, scale(IGF1_ng_ml))
```
---
## dplyr::mutate - (pt2)
_Mutate_ creates a named variable based on some form of computation
```{r}
# A new variable is created called IGFngml_zscore, based on the 
# calculation of the z-score of the variable IGF1_ng_ml using scale()
mutate(df1, IGFngml_zscore = scale(IGF1_ng_ml))
```

---
## CHALLENGE
<p>&nbsp;</p>
_ Create a dataframe with a new variable that contains the rank of the _length_ variable. Arrange this new data frame by _IGF_ (lowest to highest).
_ Create a dataframe with a new variable that is _IGF_/_length_. Arrange by this new variable (highest to lowest).

---
## ANSWERS
```{r}
# Create a dataframe with a new variable that contains the rank 
# of the _length_ variable. Arrange this new data frame by 
# _IGF_ (lowest to highest).
df1_A <- mutate(df1, length_rank=rank(length_mm))
arrange(df1_A, IGF1_ng_ml)

# Create a dataframe with a new variable that is _IGF_/_length_. 
# Arrange by this new variable (highest to lowest).
df1_A <- mutate(df1, IGF_perlength=IGF1_ng_ml/length_mm)
arrange(df1_A, -IGF_perlength)
```

---
## dplyr::summarize - (pt1)
_Summarize_ applies aggregating or summary function to a group i.e. counting
```{r}
# First we define the common_name as a group. 
df1_byname <- group_by(df1, common_name)

# Summarise is used to count over the grouped common_names
summarise(df1_byname, count = n())
```
---
## dplyr::summarize - (pt2)
_Summarize_ applies aggregating or summary function to a group i.e. means
```{r}
# Summarise is used to calculate mean IGF1_ng_ml over the
# grouped common_names
summarise(df1_byname, IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm = T))
```

---
## dplyr::group_by - (pt1)
_Grouping_ can also help filter within groups
```{r}
# Filter observations with the 2 smallest length_mm for each grouped common_names
filter(df1_byname, rank(length_mm) <= 2)
```
---
## dplyr::group_by - (pt2)
_Grouping_ can also help filter within groups
```{r}
# Filter observations with at least 5 for each grouped common_names
filter(df1_byname, n() > 5)
```
---
## dplyr::group_by - (pt3)
_Grouping_ creates a new variable based on some form of computation within the group
```{r}
# A new variable is created using z-score within the grouped common_names
mutate(df1_byname, IGFngml_zscore = scale(IGF1_ng_ml))
```

---
## CHALLENGE

1. Group df1 by the variable _age_class_. 
2. Filter to get the biggest 5 by the variable _length_ in each group. 
3. Summarise this data frame over the variable _length_ by calculating the mean. 

---
## ANSWERS

```{r}
# Group df1 by the variable _age_class_. 
df1_A <- group_by(df1, age_classbylength)

# Filter to get the biggest 5 by the variable _length_ in each group. 
df1_A <- filter(df1_A, rank(-length_mm) <= 5)

# Summarise this data frame over the variable _length_ by calculating the mean.
summarise(df1_A, mean_length_mm = mean(length_mm, na.rm = T))

```

---
# Piping to string functions together

Piping was allows you to pass the result from one expression directly into another.  
magrittR package developed the %>% pipe which is integral to the tidy way of formatting code

 -> same graphic as before , but extend
 https://github.com/trinker/tidyr_in_a_nutshell

---
## Piping vs. not piping
```{r}
# Without pipe
df1_byname <- group_by(df1, common_name)
summarise(df1_byname, IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm=T))

# With pipe
df1 %>% 
  group_by(common_name) %>% 
  summarise(IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm=T))
```

---
## Linking functions with pipes - (pt1)
```{r}
# (1) Group by common_name
# (2) Filter to all those that have length bigger then 200
# (3) Summarise is used to calculate mean IGF1_ng_ml over the grouped 
# common_names for these larger fish

df1 %>%
  group_by(common_name) %>% 
  filter(length_mm > 200) %>% 
  summarise(IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm = T))
```
---
## Linking functions with pipes - (pt2)
```{r}
# (1) Create new variable that is discrete label depending on size of the fish
# (2) Group by common_name and size
# (3) Summarise is used to calculate mean IGF1_ng_ml over the grouped 
# common_names and sizes

df1 %>%
  mutate(size = if_else(length_mm > 200, 'big_fish', 'small_fish')) %>% 
  group_by(common_name, size) %>% 
  summarise(IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm = T))
```
---
## Linking functions with pipes - (pt3)
```{r}
# (1) Create new variable that is discrete label depending on size of the fish
# (2) Group by common_name and size
# (3) Summarise is used to calculate mean IGF1_ng_ml over the grouped 
# common_names and sizes
# (4) Filter out Coho and Sockeye salmon

df1 %>%
  mutate(size = if_else(length_mm > 200, 'big_fish', 'small_fish')) %>% 
  group_by(common_name, size) %>% 
  summarise(IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm = T)) %>%
  filter(common_name != 'Coho salmon')  %>%
  filter(common_name !='Sockeye salmon')
```

---
## You can pipe straight to plots - (pt1)
```{r, warning=F, message=F}

p <- mutate(df1,size=if_else(length_mm>200, 'big_fish', 'small_fish')) %>% 
  group_by(common_name, size) %>% 
  summarize(IGF1_ng_ml_ave=mean(IGF1_ng_ml, na.rm=T)) %>% 
  filter(common_name != 'Coho salmon')  %>% 
  filter(common_name != 'Sockeye salmon') %>% 
  ggplot(aes(x = common_name, y = IGF1_ng_ml_ave, group = size, fill = size)) +
  geom_bar(stat = "identity", position = "dodge") + 
  theme(axis.text.x = element_text(angle = 90)) +
  scale_fill_brewer(palette = "Paired")
```
---
## You can pipe straight to plots - (pt2)
```{r, warning=F, message=F}
p
```

---
## CHALLENGE

1. Filter to only look at _juvenile_ in variable 
2. Group by common_name
3. Create new variable that is z-score of _length_ across groups
4. Create boxplot of grouped length zscores

---
## ANSWER
```{r}

df1 %>% 
  filter(age_classbylength == 'yearling') %>%
  group_by(common_name) %>% 
  mutate(length_zscore = scale(length_mm)) %>%
  ggplot(aes(x = common_name, y = length_zscore)) +
  geom_boxplot(fill=c('gold','darkorange'))
  
```

---
# readr: Reading data into R
So we blasted through what being tidy can give you. 
Now lets start from the beginning and tidy some data. First step is to read in data. 

readr:

_ read_csv(): comma separated (CSV) files  
_ read_tsv(): tab separated files  
_ read_delim(): general delimited files  
_ read_fwf(): fixed width files  
_ read_table(): tabular files where columns are separated by white-space  
_ read_log(): web log files   

---
## Reading in with base
```{r}

untidy_counts_base <- read.csv("dataset/hemato_rnaseq_counts.csv")
# Base will print out everything
untidy_counts_base
```
---
## Reading in with readr - (pt1)
```{r}
# readr gives you a tibble. 
read_csv("dataset/hemato_rnaseq_counts.csv")

```
---
## Reading in with readr - (pt2)
```{r}
# Tibbles carry and display extra information. 
# While reading in it is easy to specify data type. 
untidy_counts <- read_csv("dataset/hemato_rnaseq_counts.csv", col_types = cols(
    ENTREZ = col_character(),
    CD34_1 = col_integer(),
    ORTHO_1 = col_integer(),
    CD34_2 = col_integer(),
    ORTHO_2 = col_integer()
  ))
untidy_counts
```

---
## Subsetting to make tibbles - (pt1)
```{r}
# Can use the same way as base to interact with the 
# tibble dataframe - columns
untidy_counts[,1]
```
---
## Subsetting to make tibbles - (pt2)
```{r}
# Can use the same way as base to interact with the
# tibble dataframe - rows
untidy_counts[1,]
```
---
## Subsetting to make tibbles - (pt3)
```{r}
# Can also not specify which dimension you pull from. 
# This will default to grabbing the column
untidy_counts[1]
```
---
## Subsetting to make vectors - (pt1)
```{r}
# All the prior outputs have been outputting another tibble. 
# If double brackets are used a vector is returned 
untidy_counts[[1]]
```
---
## Subsetting to make vectors - (pt2)
```{r}
# This is also the case if you use the dollar and colname 
# to access a column
untidy_counts$ENTREZ
```

---
## CHALLENGE

_ Read in count data as different data types. What happens when we extract the vector of these counts?

---
## ANSWER
```{r}
untidy_counts_test <- read_csv("dataset/hemato_rnaseq_counts.csv", col_types = cols(
    ENTREZ = col_character(),
    CD34_1 = col_integer(),
    ORTHO_1 = col_character(),
    CD34_2 = col_factor(),
    ORTHO_2 = col_logical()
  ))

untidy_counts_test$CD34_1 %>% head(n=8)
untidy_counts_test$ORTHO_1 %>% head(n=8)
untidy_counts_test$CD34_2 %>% head(n=8)
untidy_counts_test$ORTHO_2 %>% head(n=8)
```

---
## Tibbles: Converting to tibble - (pt1)
```{r}
# Can convert base dataframes into tibbles
as_tibble(untidy_counts_base)
```
---
## Tibbles: Converting to tibble - (pt2)
```{r}
# Once it is a tibble it is straight forward to modify the datatype
untidy_counts_base <- as_tibble(untidy_counts_base) %>%
  mutate_at(vars(ENTREZ), as.character)
untidy_counts_base
```
---
## Tibbles: Converting from tibble
```{r}
# Some tools are not tibble friendly. Calling as.data.frame is 
# sufficient to convert it back to a base data frame
as.data.frame(untidy_counts_base) %>% head(n=12)
```

---
## Tibbles: Make your own - (pt1)
__We will make our own tibble now from scratch, using some metadata that will be useful later__
```{r, eval=F, echo=T}
# Lets load in some packages
library(org.Hs.eg.db)
library(TxDb.Hsapiens.UCSC.hg19.knownGene)

# Lets use the ENTREZ ID as a key
keys <- untidy_counts$ENTREZ

# We can use the ENTREZ ID to look up Gene Symbol
symbols <- select(org.Hs.eg.db, keys = keys,columns = "SYMBOL", keytype = "ENTREZID")

# We can use the ENTREZ ID to look up the chormosome the gene resides on
chrs <- select(TxDb.Hsapiens.UCSC.hg19.knownGene, keys = keys, columns = "TXCHROM", keytype = "GENEID")

# We can use the ENTREZ ID to get a list of genes with grange of their exons
geneExons <- exonsBy(TxDb.Hsapiens.UCSC.hg19.knownGene,by = "gene")[keys]

```

```{r, warning=FALSE, message=FALSE, cache=T, eval=T, echo=F}
# Lets load in some packages
library(org.Hs.eg.db)
library(TxDb.Hsapiens.UCSC.hg19.knownGene)

# Lets use the ENTREZ ID as a key
keys <- untidy_counts$ENTREZ

# We can use the ENTREZ ID to look up Gene Symbol
symbols <- AnnotationDbi::select(org.Hs.eg.db, keys = keys,columns = "SYMBOL", keytype = "ENTREZID")

# We can use the ENTREZ ID to look up the chormosome the gene resides on
chrs <- AnnotationDbi::select(TxDb.Hsapiens.UCSC.hg19.knownGene, keys = keys, columns = "TXCHROM", keytype = "GENEID")

# We can use the ENTREZ ID to get a list of genes with grange of their exons
geneExons <- exonsBy(TxDb.Hsapiens.UCSC.hg19.knownGene,by = "gene")[keys]

```
---
## Tibbles: Make your own - (pt2)
```{r, echo=T,eval=F}
# We will then use an apply to get the transcript length from each gene in the 
# list. The transcript length is calculated by first flattening overlapping 
# exons with reduce(), then calculating the length of each exon with width(), 
# then summing upthe total exon length to get our transcript length. 
txsLength <- sapply(geneExons, function(x){ x %>%
    GenomicRanges::reduce() %>%
    width() %>%
    sum() })

# Finally we have all this metadata. Lets put it together into a tibble. 
counts_metadata <- tibble(ID = symbols$ENTREZID, SYMBOL = symbols$SYMBOL, CHR = chrs$TXCHROM, LENGTH = txsLength)
```
```{r, eval=T, echo=F}
txsLength <- sapply(geneExons, function(x){ x %>%
    GenomicRanges::reduce() %>%
    width() %>%
    sum() })
```
# Finally we have all this metadata. Lets put it together into a tibble. 
counts_metadata <- tibble(ID = symbols$ENTREZID, SYMBOL = symbols$SYMBOL, CHR = chrs$TXCHROM, LENGTH = txsLength)
---
## Tibbles: Make your own - (pt3)
```{r}
counts_metadata
```

---
# Tidying data up

What is wrong with the count dataframe from a tidy viewpoint?  

_Remember_. These are the rules:

_ Each variable has its own column
_ Each observation has its own row
_ Each value has its own cell

```{r}
untidy_counts
```

---
## Tidying data up

What is wrong with the count dataframe from a tidy viewpoint?  

_Remember_, these are the rules:

_ Each variable has its own column
_ Each observation has its own row
_ Each value has its own cell

__A single variable with multiple columns__

```{r}
untidy_counts
```

---
## Reshape data with gather and spread

When all the content is in the data frame, but it is in the wrong orientation, tidyr has some tools to move the data around quickly and easily:  

__gather and spread__

---
## tidyr::gather 
Gather allows you to collapse single varibles that are spread over multiple columns
```{r}
# New columns Sample and Counts are created from whole dataframe
tidier_counts <- gather(untidy_counts, key="Sample", value="counts", -ENTREZ)
tidier_counts

```
---
## tidyr::spread
Spread allows you to spread single variables over multiple columns
```{r}
spread(tidier_counts, key="Sample", value="counts")
```
---
## tidyr::pivot_longer/pivot_wider
Gather and spread are being retired. They are being replaced with pivot_tools.  
There is slightly different nomencalture, but they pretty much do the same thing.
```{r, eval=F, echo=T}
#
pivot_longer(untidy_counts,names_to = "Sample", values_to = "counts", cols = c(-ENTREZ))
gather(untidy_counts, key=Sample, value=counts, -ENTREZ)
# 
pivot_wider(tidier_counts, names_from = c(Sample), values_from = counts)
spread(tidier_counts, key=Sample, value=counts)
```

---
## CHALLENGE

_ tidy up df2

---
## ANSWER
```{r}

df2 %>% 
  spread(value = value, key = variable)

```

---
## What is next to tidy?

_Remember_, these are the rules:

_ Each variable has its own column
_ Each observation has its own row
_ Each value has its own cell

```{r}
tidier_counts
```

---
## What is next to tidy?

_Remember_, these are the rules:

_ Each variable has its own column
_ Each observation has its own row
_ Each value has its own cell

__Multiple variables in a single column__

```{r}
tidier_counts
```

---
## Splitting and combining varaibles

When there are several variables crammed into a single column, tidyr can be used to split single values into several:  

__separate__

---
## tidyr::separate - (pt1)
```{r}
# Separate allows you to break a strings in a variable by a separator.
# In this case the cell type and replicate number are broken by underscore
tidier_counts <- separate(tidier_counts, Sample, sep = "_", into=c("CellType","Rep"), remove=TRUE)
tidier_counts
```
---
## tidyr::unite
```{r}
# Unite can go the other way. This can sometime be useful i.e. if you want a specific sample ID
unite(tidier_counts, Sample, CellType, Rep, remove=FALSE)
```
---
## tidyr::separate - (pt2)
```{r}
# Remember you can always pipe everything together into a single expression
tidy_counts <- untidy_counts %>% 
  gather(key=Sample, value=counts, -ENTREZ) %>% 
  separate(Sample, sep = "_", into = c("CellType","Rep"), remove=FALSE)
tidy_counts
```

---
# Joining
Data frames can be joined on a shared variable _a.k.a._ a key. We want this key to be unique i.e. ENTREZ ID. 
---
## dplyr::inner_join - Merging dataframes
```{r}
tidy_counts
```
---
## dplyr::inner_join - Merging dataframes
```{r}
counts_metadata
```
---
## dplyr::inner_join - Merging dataframes
```{r}
inner_join(tidy_counts, counts_metadata, by = c("ENTREZ" = "ID"))
```

---
## There are many ways to join things

Inner Join 

_ Keeps all observations in x and y with matching keys

Outer Join

_ A left join keeps all observations in x and those in y with matching keys.
_ A right join keeps all observations in y and those in x with matching keys. 
_ A full join keeps all observations in x and y

---
## EXAMPLE - Look at just expressed genes
```{r}
# In this pipe I group by gene, summarise the data based on the
# sum of counts, and filter for anything that has a count greater
# than 0. 
expressed_genes <- tidy_counts %>% 
  group_by(ENTREZ) %>% 
  summarise(count_total=sum(counts)) %>% 
  filter(count_total>0)
expressed_genes
```
---
## dplyr::left_join 
```{r}
# Left join shows all genes as my full data frame tidy_counts is 
# used as the backbone. The filtered expressed genes is secondary, 
# and has missing values (unexpressed genes) which are filled with NA
left_join(tidy_counts, expressed_genes, by = c("ENTREZ" = "ENTREZ"))
```
---
## dplyr::right_join
```{r}
# Right join shows only genes that survived filtering as it is using 
# the second dataframe as the backbone for the new dataframe. 
tidy_counts_expressed <- right_join(tidy_counts, expressed_genes, by = c("ENTREZ" = "ENTREZ"))
tidy_counts_expressed %>% print(n=20)
```

---
## Filtering joins

Filtering joins 

_ A semi join only keeps all observations in x that are matched in y. y isn't returned. 
_ A anti join only keeps all observations in x that are _not_ matched in y. y isn't returned. 

---
## dplyr::semi_join
```{r}
# Semi join only keeps observations in x that are matched in y. y is 
# only used as a reference and is not in output
semi_join(tidy_counts, expressed_genes)
```
---
## dplyr::anti_join
```{r}
# Anti join only keeps observations in x that are not matched in y. 
# y is only used as a reference and is not in output
anti_join(tidy_counts, expressed_genes)

```

---
## CHALLENGE
 
_ Calculate CPMs and TPMs

-> Show diagram of the math

---
## ANSWER
```{r, warning=FALSE, message=FALSE}

# Use Group to focus computation on each sample. Use mutate to make 
# new variable that is the CPM
tidy_counts_expressed <- tidy_counts_expressed  %>% 
  group_by(Sample) %>% 
  mutate(CPM=(counts/sum(counts))*1000000)

# Join our tidy data to the metadata, then make new variable that is the TPM
tidy_counts_expressed <- tidy_counts_expressed %>% 
  inner_join(counts_metadata, by = c("ENTREZ" = "ID")) %>%  
  mutate(TPM=(counts/(LENGTH/1000))/(sum(counts)/1000000))

# Simple X-Y plot comparing TPM and CPM. 
p <- tidy_counts_expressed %>% 
  ggplot(aes(x=CPM, y=TPM)) + 
  geom_point() + 
  scale_x_continuous(name="log2(CPM)",trans='log2') + 
  scale_y_continuous(name="log2(TPM)",trans='log2')
p
```

---
# Readr again: Writing out 
You've made a lovely new tibble file. Now you need to save it somewhere. 
```{r}
#Theres a wide range of writing  options. Can specify the delmiter directly or use a specific function
write_delim(tidy_counts_expressed, '../expressed_genes_output.csv', delim =',')

write_csv(tidy_counts_expressed, '../expressed_genes_output.csv')
```

A key difference compared to base is that it does not write out row names. Tibbles generally don't have rownames.

---
## tidyverse so far
__At this point we have covered or touched on the most essential facets of tidy__  
_ ~~ggplot2 – making pretty graphs~~ 
_ ~~readr – reading data into R~~  
_ ~~dplyr – manipulating data~~  
_ ~~tibble - working with tibbles~~  
_ ~~tidyr – miscellaneous tools for tidying data~~
_ purrr - iterating over data  
_ stringr – working with strings  
_ forcats - working with factors  

---
# purrr - Functional programming 

_ Applying functions to datasets  
_ Base people use _for_ loops or apply  
_ Big advantage is that purrr readily handles nested dataframes and has standard outputs

---
## purrr::map - tidy way to iterate - (pt1)
```{r}
# Map is the tidy equivalent to apply. Here we take our untidy counts, 
# trim of IDs, and then calculate means for each column. By default the 
# output is a list
untidy_counts %>% 
  dplyr::select(-ENTREZ) %>% 
  map(mean)
```
---
## purrr::map - tidy way to iterate - (pt2)
```{r}
# Same as the above line, but using map_dbl specifies the outputs is 
# going to be a double
untidy_counts %>% 
  dplyr::select(-ENTREZ) %>% 
  map_dbl(mean)
```
---
## With tidy data - summarize sometimes
```{r}
# Summary sometimes also works in this context
tidy_counts %>% 
  group_by(Sample) %>% 
  summarize(mean_counts = mean(counts))
```
---
## With tidy data - the purrr way
```{r}
# This is an alternative method for doing this with an tidied frame
tidy_counts %>% 
  split(.$Sample) %>% 
  map_dbl(~mean(.$counts))
```
---
## purrr::pmap for multiple inputs
```{r}
# pmap is a map variant for dealing with multiple inputs. This can be 
# used to apply a function on a row by row basis
list(untidy_counts$ORTHO_1, untidy_counts$ORTHO_2) %>% 
  pmap_dbl(mean)

```

---
## Nest - Values can be much more

Dataframes can be be simplified by making them more complex.  

Each value within a tibble can contian more abstract information then just numbers and chracters. Instead you can store another tibble, or object.

---
## tidyr::nest - (pt1)
```{r}
# Nest all the data by sample
tidy_counts_nest <- tidy_counts_expressed %>% 
  group_by(Sample) %>%
  nest()

# Looking at tibble it is a new datatype that appears simplified
tidy_counts_nest

tidy_counts_nest$data %>% is()
```
---
## tidyr::nest - (pt2)
```{r}
# The data is still there, nested within one of the variables
tidy_counts_nest$data[[1]]
```
---
## tidyr::nest and purrr::map
```{r}
# Map can be used to apply functions across nested dataframes.
# Here we calculate a linear model. This is also saved in the tibble. 
tidy_counts_nest <- tidy_counts_nest %>% 
  mutate(my_model = map(data, ~lm(CPM ~ TPM, data = .)))

tidy_counts_nest

tidy_counts_nest$my_model[[1]]
```
---
## broom::tidy - making models legible 
```{r}
# Tidy also has the ability to "tidy" up outputs from common statistical 
# packages, using broom.
library(broom)

tidy_counts_nest <- tidy_counts_nest %>% 
  mutate(my_tidy_model = map(my_model, broom::tidy))

tidy_counts_nest
```
---
## broom::tidy - making models legible 
```{r}
tidy_counts_nest$my_tidy_model[[1]]
```

---
## dplyr::unnest - expand out - (pt1)
```{r}
# Unnesting to get everything back into a dataframe is very straightforward
tidy_counts_nest %>%
  unnest(my_tidy_model)
```
---
## dplyr::unnest - expand out - (pt2)
```{r}
# Unnesting can be done sequentially to keep adding to master dataframe
tidy_counts_nest %>%
  unnest(my_tidy_model) %>% 
  unnest(data)

```

---
## CHALLENGE

---
## ANSWER
```{r}


```

---
# stringr - working with strings

If the data you are working with involves characters from data entry often there will be errors i.e. clinical study metadata or a hand-typed list of genes of interest. Tidying data also means fixing these problems. stringr helps make this easy. 

* Access and manipulate characters
* Deal with whitespace
* Pattern Recognition

Though stringr is pretty comprehensive and covers most of what you will need, there is a sister package called stringi with even more functionality. 

---
## stringr::strsub - string basics
Many overlapping functions with base for combining, subsetting, converting and finding strings

```{r}

brc <- c("Tom", "Ji-Dung", "Matt")

# Extract substrings from a range. Here the 1st to 3rd character
brc %>% str_sub( 1, 3)

# Extract substrings from a range. Here the 2nd to 2nd to last character
brc %>% str_sub( 2, -2)


# Assign values back to substrings. Here the 2nd to 2nd to last character is replaced with X.
str_sub(brc, 2, -2)<-'X'
brc
```

---
## stringr::str_trim - stripping whitespace

```{r}
brc2 <- c("Tom  ", "  Ji  -Dung", "Matt   ")

# Trim whitespace from strings
brc2 <- str_trim(brc2)
brc2 

# Can add whitespace to strings to get consistent length. Here all are 10 characters
str_pad(brc2, width=10, side='left')
```

---
## stringr::str_to_* - Capitalization - (pt1)
```{r}
# Lets reuse our counts tibble. pull from dplyr can be used to grab a tibble 
# column and make it into a vector
tidy_counts_expressed %>% 
  pull(SYMBOL) %>%
  head()

# Here we pull our gene symbols from our tibble into a vector, and then convert 
# them into title style capitalization
tidy_counts_expressed %>% 
  pull(SYMBOL) %>% 
  str_to_title() %>% 
  head()
```
---
## stringr::str_to_* - Capitalization - (pt2)
```{r}
# String manipulation functions can be used on tibbles using mutate. Here we convert
# gene symbols to title style capitalization
tidy_counts_expressed %>% 
  mutate(SYMBOL = str_to_title(SYMBOL))
```
---
## stringr::str_to_* - Capitalization - (pt3)
```{r}
# Here we convert chromosome annotation to capitals
tidy_counts_expressed %>% 
  mutate(CHR = str_to_upper(CHR))
```

---
## stringr::detect - which have pattern?
```{r}
# Find patterns in different ways
# Detect gives a T/F whether the pattern 'salmon' is present in vector
df1 %>% 
  pull(common_name) %>% 
  str_detect('salmon')
```
---
## stringr::detect - give me only patterns
```{r}
# Subset returns the match if the pattern 'salmon' is present in vector
df1 %>% 
  dplyr::pull(common_name) %>% 
  str_subset('salmon') 
```
---
## stringr::str_ends - ends with pattern?
```{r}
# Ends is similar to detect as it gives gives a T/F whether the pattern 'salmon' 
# is present in vector, but the pattern has to be at the end. 
df1 %>% 
  dplyr::pull(common_name) %>% 
  str_ends('salmon') 

df1 %>% 
  filter(str_ends(common_name,'salmon'))
```
---
## stringr::str_count - how many patterns?
```{r}
#Count gives you the total number of times your pattern appears in each chracter in the vector
df1 %>% 
  dplyr::pull(common_name) %>% 
  str_count('salmon')

df1 %>% 
  dplyr::pull(common_name) %>% 
  str_count('o')
```
---
## stringr::str_replace_all - replace a string
```{r}
#Replace
df1 %>% 
  dplyr::pull(common_name) %>%
  str_replace_all('Steelhead','Steelhead trout' )
```
---
## stringr::str_replace_all - replace a string
```{r}
df1 %>% 
  mutate(common_name = str_replace_all(common_name,'Steelhead','Steelhead trout' ))
```

---
## CHALLENGE

---
## ANSWER
```{r}


```

---
# forcats - Handling factors

Factors are a data type that R uses to handle fixed categorical variables that have a known set of possible values. 

Factors are ordered, allowing hierachy to be preserved in relatively simple vectors.

---
## Making a factor - Vectors
_[This is base]_
```{r}
# Vectors are easy to turn into factors with factor()
tidy_counts_expressed_samples <- tidy_counts_expressed %>% 
  pull(Sample) %>% 
  factor() 

tidy_counts_expressed_samples %>% head(n=10)
```
---
## Making a factor - Tibbles
```{r}
# Can also modify the data type of a tibble column with as_facotr, in an approach we have used before.
tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) 
```
---
## Making a factor - Tibbles
```{r}
tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>% 
  pull(Sample) %>% head(n=10)
```
---
## Making a factor - Controlling levels
```{r}
# When you factorize you can use a vector to determine the order
my_levels1<-c('ORTHO_1','ORTHO_2','CD34_1','CD34_2')
tidy_counts_expressed %>% 
  pull(Sample) %>% 
  factor(levels = my_levels1 ) %>% head(n=10)

# When you factorize anything not in the given levels is turned to NA
my_levels2<-c('ORTHO_1','CD34_1')
tidy_counts_expressed %>% 
  pull(Sample) %>% 
  factor(levels = my_levels2 ) %>% head(n=10)

# Its straightforward to grab the levels from the factor
tidy_counts_expressed_samples %>% 
  levels()

```

---
## Why do we factorize? For order. 
```{r}

p <- tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>% 
  group_by(Sample) %>% 
  summarize(mean_count=mean(counts)) %>% 
  ggplot(aes(x=Sample, y= mean_count)) + 
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))
```
---
## Why do we factorize? For order. 
```{r}
p
```

---
## forcats::fct_relevel - Reorder manually
```{r}
# fct_relevel - reorder manually
tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>%
  mutate(Sample = fct_relevel(Sample, my_levels1)) %>% 
  pull(Sample) %>% head(n=10)

# fct_relevel - reorder manually
tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>%
  mutate(Sample = fct_relevel(Sample, my_levels2)) %>% 
  pull(Sample) %>% head(n=10)

```
---
## forcats::fct_reorder - Reorder using data
```{r}
# fct_reorder - reorder based on the data. Here we are ordering based
# on mean counts for each sample.
tidy_counts_expressed %>%
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>% 
  mutate(Sample = fct_reorder(Sample, counts, mean)) %>% 
  pull(Sample) %>% head(n=10)

```

---
## Now our ordering can be fixed
```{r}

p <- tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>%
  mutate(Sample=fct_relevel(Sample, my_levels1)) %>% 
  group_by(Sample) %>% 
  summarize(mean_count=mean(counts)) %>% 
  ggplot(aes(x=Sample, y= mean_count)) + 
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))
```
---
## Now our ordering can be fixed 
```{r}
p
```

---
## forcats::fct_recode - Change levels
```{r}

df1$age_classbylength

# Recoding levels to give them a new name
df1 %>% 
  mutate_at(vars(age_classbylength), as_factor) %>%
  mutate(age_classbylength=fct_recode(age_classbylength, "mixed juvenile" = "mixed age juvenile")) %>%
  pull(age_classbylength)

# Recoding levels to change to add one factor to another factor
df1 %>% 
  mutate_at(vars(age_classbylength), as_factor) %>% 
  mutate(age_classbylength=fct_recode(age_classbylength, "juvenile" = "mixed age juvenile")) %>%
  pull(age_classbylength)

```
---
## forcats::fct_count() - Summarise by counting
```{r}
# fct_count - Count up the number of each
df1 %>% 
  mutate_at(vars(age_classbylength), as_factor) %>% 
  pull(age_classbylength) %>% 
  fct_count()
```
---
## forcats::fct_infreq() - Mask rare factors
```{r}
# fct_infreq - mask rare factors by giving them a general summary term i.e. Other
df1 %>% 
  mutate_at(vars(age_classbylength), as_factor) %>%
  mutate(age_classbylength=fct_lump(age_classbylength, n=2)) %>%
  pull(age_classbylength)

df1 %>% 
  mutate_at(vars(age_classbylength), as_factor) %>%
  mutate(age_classbylength=fct_lump(age_classbylength, n=2)) %>%
  pull(age_classbylength) %>% 
  fct_count()
```
---
## forcats::fct_c - Combining factors
```{r}
# Normally facotrs do not like to be combined as levels in one may not exist in the other.
# Factor concatenation with fct_c help get around this. 
A <- factor(c('Tom','Ji-Dung'))
B <- factor('Matt')
fct_c(A, B)
```

---
## CHALLENGE
short/long genes
---
## ANSWER
```{r}


```
---
# Summary 
We have covered the core packages in the tidyverse  

_ ~~ggplot2 – making pretty graphs~~ 
_ ~~readr – reading data into R~~  
_ ~~dplyr – manipulating data~~  
_ ~~tibble - working with tibbles~~  
_ ~~tidyr – miscellaneous tools for tidying data~~
_ ~~purrr - iterating over data~~
_ ~~stringr – working with strings~~  
_ ~~forcats - working with factors~~  

---
## Tidy beyond this workshop

Hadley Wickham (Chief Scientist at RStudio) is the driving force behind the tidyverse.  

Hadley wrote a paper about why he thinks tidy data is best: www.jstatsoft.org/v59/i10/paper.  

There is a lot of support for all things tidy at: https://www.tidyverse.org/  
(This includes really great cheat sheets for each tool)

---
## Tidy packages to check out:

plyranges: dplyr equivalent for working with ranges i.e. Granges

readxl: This package is very useful when you want to import Excel sheets in R

googledrive: Interact with your googledrive through R

lubridate and hms: Allow managin of calendar and time formats

magrittr: piping tools

broom: helps tidy up standard base function i.e. lm or t.test

tidymodels: A collection of tools for preparing for and validating model functions

---
## Other Good Resources

ggplot  
https://rockefelleruniversity.github.io/Plotting_In_R/

R for Data Science text book  
https://r4ds.had.co.nz/

Data Science with R text book
http://garrettgman.github.io/

Cancer Research UK - Intermediate R course
https://bioinformatics-core-shared-training.github.io/r-intermediate/

---
# Thanks

_BRC_
Tom Carroll: tcarroll@rockefeller.edu
Ji-Dung Luo: jluo@rockefeller.edu
Matt Paul: mpaul@rockefeller.edu

_Data Science Group_
Eli Stoyanova
Doug Barrows
Greg Gedman




