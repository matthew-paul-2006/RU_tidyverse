---
title: "Getting tidy <html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>"
author: "Rockefeller University, Bioinformatics Resource Centre"
date: "http://rockefelleruniversity.github.io/Intro_To_R_1Day/"
output: 
  xaringan::moon_reader:
    css: ["default", "metropolisCustom.css", "metropolis-fontsCustom.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
  html_document:
    toc: true # table of content true
    toc_float: yes
    depth: 3  # upto three depths of headings (specified by #, ---
## and ---
###)
## if you want number sections at each table header
    theme: united  # many options for theme, this one is my favorite.
    highlight: tango  # specifies the syntax highlighting style
params:
  isSlides: "no"

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
---
## BRC - Bioinformatics Resource Center

<p>&nbsp;</p>

We are your local friendly bioinformaticians. 

<p>&nbsp;</p>

We want to help with your problematic data. New or Old.

<p>&nbsp;</p>

Drop by and say Hi!

---
# Data Wrangling with Tidy

**Some problems we face when dealing with data regularly.**  

Every dataset is different. Sometimes very different.

There are many ways to do things. Everyone has their favorite syntax. 

**The issue:**  
Many fundamental data processing functions exist in *Base R* and beyond. Sometimes they can be inconsistent or unnecessarily complex. Especially when dealing with non-standard dataframes. The result is code that is confusing and doesn't flow i.e. nested functions

---
## What does it mean to be tidy?

Tidyverse is most importantly a philosophy for data analysis that more often then not makes wrangling data easier. The tidyverse community have built what they describe as an "opinionated" group of packages. These packages readily talk to one another. 

* More efficient code
* Easier to remember syntax
* Easier to read syntax

Their manifesto: https://cran.r-project.org/web/packages/tidyverse/vignettes/manifesto.html

---
## What does it actually mean to be tidy?
<p>&nbsp;</p>
* A defined vision for coding style in R  
* A defined vision for data formats in R
* A defined vision for package design in R
* Unified set of community pushing in a cohesive direction
* Critical mass of people to influence the way the whole R community evolves

---
## What are the main tidy tools?
<p>&nbsp;</p>
* ggplot2 – making pretty graphs 
* readr – reading data into R  
* dplyr – manipulating data  
* tibble - working with tibbles  
* tidyr – miscellaneous tools for tidying data
* purrr - iterating over data  
* stringr – working with strings  
* forcats - working with factors  

Other tools have now been made for the tidy community. This community also overlaps with bioconductor. But the packages above are the linchpins that hold it together. 

---
## What are we doing today

Workflow Image for working with data.

---
## What we won't be doing today
<p>&nbsp;</p>
We already have a course online for plotting, including ggplot.     

https://rockefelleruniversity.github.io/Plotting_In_R/

---
# Lets get tidy!
**First step lets load in the data we are using today**
```{r}
cat(getwd())
load(file='dataset/my_tidy.Rdata')
```

---
## Are all data frames equal - (pt1)?
```{r,eval=FALSE,echo=TRUE}
head(df1)
```

```{r,eval=TRUE,echo=FALSE}
utils::head(df1)
```

```{r,eval=FALSE,echo=TRUE}
head(df2)
```

```{r,eval=TRUE,echo=FALSE}
utils::head(df2)
```

---
## Are all data frames equal - (pt2)?
```{r,eval=FALSE,echo=TRUE}
head(df3a)
```

```{r,eval=TRUE,echo=FALSE}
utils::head(df3a)
```

```{r,eval=FALSE,echo=TRUE}
head(df3b)
```

```{r,eval=TRUE,echo=FALSE}
utils::head(df3b)
```

---
## What is a tidy dataset?

A tidy dataset is a data frame (or table) for which the following are true:

* Each variable has its own column
* Each observation has its own row
* Each value has its own cell

**Which of our dataframes is tidy?**

---
## Which is a tidy dataset?

A tidy dataset is a data frame (or table) for which the following are true:

* Each variable has its own column
* Each observation has its own row
* Each value has its own cell

**Which of our dataframes is tidy?**  
Our first dataframe is tidy

---
## Why bother?

Consistent dataframe layouts help to ensure that all values are present and that relationships between data points are clear.

R is a vectorized programming language. R builds data frames from vectors, and R works best when its operation are vectorized. Tidy data utilizes of both of these aspects of R.

=> Precise and Fast

---
## Lets load in the tidyverse
```{r}
library(tidyverse)
```

---
## These tools have same logic

 -> insert graphic here
 https://github.com/trinker/tidyr_in_a_nutshell

---
# dplyr
This package contains a variety of tools to access and manipulate dataframes.

---
# dplyr::select - (pt1)
**Select** allows you to make a vector from a specific variable
```{r}
# Select one variable (common_name)
select(df1, common_name)
```

---
# dplyr::select - (pt2)
**Select** allows you to make a dataframe from several variables
```{r}
# Select two variables (age_classbylength and common_name)
select(df1, age_classbylength, common_name)
```

---
# dplyr::select - (pt3)
**Select** allows you to make a dataframe excluding a variable
```{r}
# Select all but one variable (length_mm)
select(df1,-length_mm)
```

---
# dplyr::select - (pt4)
**Select** allows you to make a dataframe from a range of variables
```{r}
# Select all a range of contiguous varibles (common_name:length_mm)
select(df1, common_name:length_mm)
```

---
# dplyr::filter - (pt1)
**Filter** allows you to access observations based on a criteria
```{r}
# Filter all observation where the variable common_name is Sockeye salmon
filter(df1, common_name == 'Sockeye salmon')
```

---
# dplyr::filter - (pt2)
**Filter** allows you to access observations based on several criteria
```{r}
# Filter all observations where the variable common_name is either Sockeye salmon or Chinook Salmon
filter(df1, common_name %in% c('Sockeye salmon', 'Chinook salmon'))
```

---
# dplyr::filter - (pt3)
**Filter** allows you to access observations based on specific strings
```{r}
# Filter all observations where the variable common_name ends with 'salmon'. To do this we use stringr function str_ends recognise strings that end with 'salmon'.
filter(df1, str_ends(common_name, 'salmon'))
```

---
# dplyr::filter - (pt4)
**Filter** allows you to access observations based on operators
```{r}
# Filter all observations where the variable length_mm is greater than 200 or less than 120
filter(df1, length_mm > 200 | length_mm < 120)
```

---
## CHALLENGE
<p>&nbsp;</p>
* Create a dataframe with the variables *age* and *IGF* for only the *Steelhead* fish
* Create a dataframe with all the variables except the *IGF* values, for all fish that begin with *S*

---
## ANSWERS
```{r}
# Create a dataframe of the variables *age* and *IGF* of only the *Steelhead* fish
df1_A <- filter(df1, common_name == 'Steelhead')
select(df1_A, age_classbylength, IGF1_ng_ml)

# Create a dataframe of all variables but the *IGF* values, for all fish that begin with *S*
df1_A <- filter(df1, str_starts(common_name,'S'))
select(df1_A, -IGF1_ng_ml)
```

---
# dplyr::arrange - (pt1)
*Arrange* sorts the dataframe based on a specific variable
```{r}
# Arrange the data based on the variable length_mm
arrange(df1, length_mm)
```
---
# dplyr::arrange - (pt2)
*Arrange* sorts the dataframe based on specific variables
```{r}
# Arrange the data first based on the variable common_name, then secondly based on length_mm in a descending order.
arrange(df1, common_name, desc(length_mm))
```

---
# dplyr::mutate - (pt1)
*Mutate* creates a new variable based on some form of computation
```{r}
# A new variable is created based on the calculation of the z-score of the variable IGF1_ng_ml using scale()
mutate(df1, scale(IGF1_ng_ml))
```
---
# dplyr::mutate - (pt2)
*Mutate* creates a named variable based on some form of computation
```{r}
# A new variable is created called IGFngml_zscore, based on the caluclation of the z-score of the variable IGF1_ng_ml using scale()
mutate(df1, IGFngml_zscore = scale(IGF1_ng_ml))
```

---
## CHALLENGE
<p>&nbsp;</p>
* Create a dataframe with a new variable that contains the rank of the *length* variable. Arrange this new data frame by *IGF* (lowest to highest).
* Create a dataframe with a new variable that is *IGF*/*length*. Arrange by this new variable (highest to lowest).

---
## ANSWERS
```{r}
# Create a dataframe with a new variable that contains the rank of the *length* variable. Arrange this new data frame by *IGF* (lowest to highest).
df1_A <- mutate(df1, length_rank=rank(length_mm))
arrange(df1_A, IGF1_ng_ml)

#Create a dataframe with a new variable that is *IGF*/*length*. Arrange by this new variable (highest to lowest).
df1_A <- mutate(df1, IGF_perlength=IGF1_ng_ml/length_mm)
arrange(df1_A, -IGF_perlength)
```

---
# dplyr::summarize - (pt1)
*Summarize* applies aggregating or summary function to a group i.e. counting
```{r}
# First we define the common_name as a group. 
df1_byname <- group_by(df1, common_name)

# Summarise is used to count over the grouped common_names
summarise(df1_byname, count = n())
```
---
# dplyr::summarize - (pt2)
*Summarize* applies aggregating or summary function to a group i.e. means
```{r}
# Summarise is used to calculate mean IGF1_ng_ml over the grouped common_names
summarise(df1_byname, IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm = T))
```

---
# dplyr::group_by - (pt1)
*Grouping* can also help filter within groups
```{r}
# Filter obsevrations with the 2 smallest length_mm for each grouped common_names
filter(df1_byname, rank(length_mm) <= 2)
```
---
# dplyr::group_by - (pt2)
*Grouping* can also help filter within groups
```{r}
# Filter obsevrations with at least 5 for each grouped common_names
filter(df1_byname, n() > 5)
```
---
# dplyr::group_by - (pt3)
*Grouping* creates a new variable based on some form of computation within the group
```{r}
# A new variable is created using z-score within the grouped common_names
mutate(df1_byname, IGFngml_zscore = scale(IGF1_ng_ml))
```

---
## CHALLENGE

1. Group df1 by the variable *age_class*. 
2. Filter to get the biggest 5 by the variable *length* in each group. 
3. Summarise this data frame over the variable *length* by calculating the mean. 

---
## ANSWERS

```{r}
# Group df1 by the variable *age_class*. 
df1_A <- group_by(df1, age_classbylength)

# Filter to get the biggest 5 by the variable *length* in each group. 
df1_A <- filter(df1_A, rank(-length_mm) <= 5)

# Summarise this data frame over the variable *length* by calculating the mean.
summarise(df1_A, mean_length_mm = mean(length_mm, na.rm = T))

```

# Piping to string functions together

Piping was allows you to pass the result from one expression directly into another.  
magrittR package developed the %>% pipe which is integral to the tidy way of formatting code

 -> same graphic as before , but extend
 https://github.com/trinker/tidyr_in_a_nutshell

---
## Piping vs. not piping
```{r}
# Without pipe
df1_byname <- group_by(df1, common_name)
summarise(df1_byname, IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm=T))

# With pipe
df1 %>% group_by(common_name) %>% summarise(IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm=T))
```

---
## Linking functions with pipes - (pt1)
```{r}
# (1) Group by common_name
# (2) Filter to all those that have length bigger then 200
# (3) Summarise is used to calculate mean IGF1_ng_ml over the grouped common_names for these larger fish
df1 %>%
  group_by(common_name) %>% 
  filter(length_mm > 200) %>% 
  summarise(IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm = T))
```
---
## Linking functions with pipes - (pt2)
```{r}
# (1) Create new variable that is discrete label depending on size of the fish
# (2) Group by common_name and size
# (3) Summarise is used to calculate mean IGF1_ng_ml over the grouped common_names and sizes
df1 %>%
  mutate(size = if_else(length_mm > 200, 'big_fish', 'small_fish')) %>% 
  group_by(common_name, size) %>% 
  summarise(IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm = T))
```
---
## Linking functions with pipes - (pt3)
```{r}
# (1) Create new variable that is discrete label depending on size of the fish
# (2) Group by common_name and size
# (3) Summarise is used to calculate mean IGF1_ng_ml over the grouped common_names and sizes
# (4) Filter out Coho and Sockeye salmon
df1 %>%
  mutate(size = if_else(length_mm > 200, 'big_fish', 'small_fish')) %>% 
  group_by(common_name, size) %>% 
  summarise(IGF1_ng_ml_ave = mean(IGF1_ng_ml, na.rm = T)) %>%
  filter(common_name != 'Coho salmon')  %>%
  filter(common_name !='Sockeye salmon')
```

---
## You can pipe straight to plots - (pt1)
```{r, warning=F, message=F}

p <- mutate(df1,size=if_else(length_mm>200, 'big_fish', 'small_fish')) %>% 
  group_by(common_name, size) %>% 
  summarize(IGF1_ng_ml_ave=mean(IGF1_ng_ml, na.rm=T)) %>% 
  filter(common_name != 'Coho salmon')  %>% 
  filter(common_name != 'Sockeye salmon') %>% 
  ggplot(aes(x = common_name, y = IGF1_ng_ml_ave, group = size, fill = size)) +
  geom_bar(stat = "identity", position = "dodge") + 
  theme(axis.text.x = element_text(angle = 90)) +
  scale_fill_brewer(palette = "Paired")
```
---
## You can pipe straight to plots - (pt2)
```{r, warning=F, message=F}
p
```

---
## CHALLENGE

1. Filter to only look at *juvenile* in variable 
2. Group by common_name
3. Create new variable that is z-score of *length* across groups
4. Create boxplot of grouped length zscores

---
## ANSWER
```{r}

df1 %>% 
  filter(age_classbylength == 'yearling') %>%
  group_by(common_name) %>% 
  mutate(length_zscore = scale(length_mm)) %>%
  ggplot(aes(x = common_name, y = length_zscore)) +
  geom_boxplot(fill=c('gold','darkorange'))
  
```

---
# readr: Reading data into R
So we blasted through what being tidy can give you. 
Now lets start from the beginning and tidy some data. First step is to read in data. 

readr:

* read_csv(): comma separated (CSV) files  
* read_tsv(): tab separated files  
* read_delim(): general delimited files  
* read_fwf(): fixed width files  
* read_table(): tabular files where columns are separated by white-space  
* read_log(): web log files   

---
## readr vs Base
```{r}

untidy_counts_base <- read.csv("dataset/hemato_rnaseq_counts.csv")
# Base will print out everything if you do not use head
head(untidy_counts_base)

# ReadR gives you a tibble. 
# Note the rownames are now their own column.
untidy_counts <- read_csv("dataset/hemato_rnaseq_counts.csv")
untidy_counts

# Tibbles carry and display extra information. While reading in it is easy to specify data type. 
untidy_counts <- read_csv("dataset/hemato_rnaseq_counts.csv", col_types = cols(
    ENTREZ = col_character(),
    CD34_1 = col_integer(),
    ORTHO_1 = col_integer(),
    CD34_2 = col_integer(),
    ORTHO_2 = col_integer()
  ))
untidy_counts
```

# Tibbles

---
## Subsetting tibbles
```{r}
#Can use the same way as base to interact with the tibble dataframe
untidy_counts[,1]
untidy_counts[1,]

#Can also not specify which dimension you pull from. This will default to grabbing the column
untidy_counts[1]

#All the prior outputs have been outputting another tibble. If double brackets are used a vector is returned 
untidy_counts[[1]]

#This is also the case if you use the dollar and colname to access a column
untidy_counts$ENTREZ
```

---
## CHALLENGE

* Read in count data as different data types. What happens when we extract the vector of these counts?

---
## ANSWER
```{r}
untidy_counts_test <- read_csv("dataset/hemato_rnaseq_counts.csv", col_types = cols(
    ENTREZ = col_character(),
    CD34_1 = col_integer(),
    ORTHO_1 = col_character(),
    CD34_2 = col_factor(),
    ORTHO_2 = col_logical()
  ))

untidy_counts_test$CD34_1 %>% head(n=8)
untidy_counts_test$ORTHO_1 %>% head(n=8)
untidy_counts_test$CD34_2 %>% head(n=8)
untidy_counts_test$ORTHO_2 %>% head(n=8)
```

---
## Converting Tibbles - Back and Forth
```{r}
# Can convert base dataframes into tibbles
as_tibble(untidy_counts_base)

# Once it is a tibble it is straight forward to modify the datatype
untidy_counts_base <- as_tibble(untidy_counts_base) %>%
  mutate_at(vars(ENTREZ), as.character)
untidy_counts_base

# Some tools are not tibble friendly. Calling as.data.frame is sufficient to convert it back to a base data frame
as.data.frame(untidy_counts_base) %>% head(n=12)
```

---
## Make your own tibble. Lets grab some metadata to do this. 
```{r, warning=FALSE, message=FALSE}
# Lets load in some packages
library(org.Hs.eg.db)
library(TxDb.Hsapiens.UCSC.hg19.knownGene)

# Lets use the ENTREZ ID as a key
keys <- untidy_counts$ENTREZ

# We can use the ENTREZ ID to look up Gene Symbol
symbols <- select(org.Hs.eg.db, keys = keys,columns = "SYMBOL", keytype = "ENTREZID")

# We can use the ENTREZ ID to look up the chormosome the gene resides on
chrs <- select(TxDb.Hsapiens.UCSC.hg19.knownGene, keys = keys, columns = "TXCHROM", keytype = "GENEID")

# We can use the ENTREZ ID to get a list of genes with grange of their exons
geneExons <- exonsBy(TxDb.Hsapiens.UCSC.hg19.knownGene,by = "gene")[keys]

# We will then use an apply to get the transcript length from each gene in the list. The transcript length is calculated by first flattening overalpping exons with reduce(), then calculating the length of each exon with width(), then summing upthe total exon length to get our transcript length. 
txsLength <- sapply(geneExons, function(x){ x %>%
    reduce() %>%
    width() %>%
    sum() })

# Finally we have all this metadata. Lets put it together into a tibble. 
counts_metadata <- tibble(ID = symbols$ENTREZID, SYMBOL = symbols$SYMBOL, CHR = chrs$TXCHROM, LENGTH = txsLength)
```

---
## Tidying data up

What is wrong with the count dataframe from a tidy viewpoint?  

*Remember*. These are the rules:

* Each variable has its own column
* Each observation has its own row
* Each value has its own cell

```{r}
untidy_counts
```

A single variable with multiple columns

---
## How do we get tidy? - Pivot tools (formerly known as gather/spread )
```{r}
# Pivot longer allows you to collapse variables single varibles that are spread over multiple columns
tidier_counts <- pivot_longer(untidy_counts, cols = c(-ENTREZ), names_to = c("Sample"), values_to = "counts")
tidier_counts

# Pivot wider allows you to spread single variables over multiple columns   
pivot_wider(tidier_counts, names_from = c("Sample"), values_from = "counts")
```

---
## CHALLENGE

* tidy up df2

---
## ANSWER
```{r}

df2 %>% pivot_wider(values_from = value, names_from = variable)

```

---
## What next?
```{r}
tidier_counts
```

Multiple variables in a single column

---
## Dealing with multiple variables in a single column

```{r}
#Seperate allows you to break a strings in a vraible by a seperator. In this case the cell type and replicate number are broken by underscore
tidier_counts <- separate(tidier_counts, Sample, sep = "_", into=c("CellType","Rep"), remove=TRUE)
tidier_counts

#Unite can go the other way if you want to generate a key. We can use this to make sure we have a Key.
unite(tidier_counts, Sample, CellType, Rep, remove=FALSE)

#Remember you can always pipe eveyrthing together into a single expression
tidy_counts <- untidy_counts %>% 
  pivot_longer(cols = c(-ENTREZ), names_to = c("Sample"), values_to = "counts") %>% 
  separate(Sample, sep = "_", into = c("CellType","Rep"), remove=FALSE)
```

# Joining: We have two related data frames. Can we link them together?

---
## Data frames can be joined on a shared variable *a.k.a.* a key
You need a key. We want this to be unique i.e. ENTREZ ID. 
```{r}
tidy_counts
counts_metadata
inner_join(tidy_counts, counts_metadata, by = c("ENTREZ" = "ID"))
```

---
## There are many ways to join things

Inner Join 

* Keeps all observations in x and y with matching keys

Outer Join

* A left join keeps all observations in x and those in y with matching keys.
* A right join keeps all observations in y and those in x with matching keys. 
* A full join keeps all observations in x and y

---
## Example - I only want to look at expressed genes

```{r}
# In this pipe I group by gene, summarise the data based on the sum of counts, and filter for anything that has a count greater than 0. 
expressed_genes <- tidy_counts %>% 
  group_by(ENTREZ) %>% 
  summarise(count_total=sum(counts)) %>% 
  filter(count_total>0)

# Left join shows all genes as my full data frame tidy_counts is used as the backbone. The filtered expressed genes is secondary, and has missing values (unexpressed genes) which are filled with NA
left_join(tidy_counts, expressed_genes, by = c("ENTREZ" = "ENTREZ")) %>% print(n=20)

# Right join shows only genes that survived filtering as it is using the second dataframe as the backbone for the new dataframe. 
tidy_counts_expressed <- right_join(tidy_counts,expressed_genes, by = c("ENTREZ" = "ENTREZ"))
tidy_counts_expressed  %>% print(n=20)
```

---
## Filtering joins. 
```{r}
#Semi join only keeps observations in x that are matched in y. y is only used as a reference and is not in output
semi_join(tidy_counts, expressed_genes)

#Anti join only keeps observations in x that are not matched in y. y is only used as a reference and is not in output
anti_join(tidy_counts, expressed_genes)

```

---
## CHALLENGE
 
* Calculate CPMs and TPMs

-> Show diagram of the math

---
## ANSWER
```{r, warning=FALSE, message=FALSE}

# Use Group to focus computation on each sample. Use mutate to make new variable that is the CPM
tidy_counts_expressed <- tidy_counts_expressed  %>% 
  group_by(Sample) %>% 
  mutate(CPM=(counts/sum(counts))*1000000)

# Join our tidy data to the metadata, then make new variable that is the TPM
tidy_counts_expressed <- tidy_counts_expressed %>% 
  inner_join(counts_metadata, by = c("ENTREZ" = "ID")) %>%  
  mutate(TPM=(counts/(LENGTH/1000))/(sum(counts)/1000000))

# Simple X-Y plot comparing TPM and CPM. 
p <- tidy_counts_expressed %>% 
  ggplot(aes(x=CPM, y=TPM)) + 
  geom_point() + 
  scale_x_continuous(name="log2(CPM)",trans='log2') + 
  scale_y_continuous(name="log2(TPM)",trans='log2')
p
```

# Readr again: Writing your lovely new tibble to file
```{r}
# A key difference compared to base is that it does not write out row names. Tibbles generally don't have rownames. 
# Theres a wide range of writing options. Can specify the delmiter directly or use a specific function
write_delim(tidy_counts_expressed, '../expressed_genes_output.csv', delim =',')

write_csv(tidy_counts_expressed, '../expressed_genes_output.csv')

```

---
## At this point we have covered or touched on the most essential facets of tidy

* ~~ggplot2 – making pretty graphs~~ 
* ~~readr – reading data into R~~  
* ~~dplyr – manipulating data~~  
* ~~tibble - working with tibbles~~  
* ~~tidyr – miscellaneous tools for tidying data~~
* purrr - iterating over data  
* stringr – working with strings  
* forcats - working with factors  

# purrr - Functional programming 

* Applying functions to datasets  
* Base people use for loops or apply  
* Big advantage is that purrr readily handles nested dataframes and has standard outputs

---
## map - tidy way to iterate over a dataset 
```{r}
# Map is the tidy equivalent to apply. Here we take our untidy counts, trim of IDs, and then calculate means for each column. By default the output is a list
untidy_counts %>% 
  dplyr::select(-ENTREZ) %>% 
  map(mean)

# Same as the above line, but using map_dbl specifies the outputs is going to be a double
untidy_counts %>% 
  dplyr::select(-ENTREZ) %>% 
  map_dbl(mean)

# Summary also works in this context
tidy_counts %>% 
  group_by(Sample) %>% 
  summarize(mean_counts = mean(counts))

# This is an alternative method for doing this with an tidied frame
tidy_counts %>% 
  split(.$Sample) %>% 
  map_dbl(~mean(.$counts))

# pmap is a map variant for dealing with multiple inputs. This can be used to apply a function on a row by row basis
list(untidy_counts$ORTHO_1, untidy_counts$ORTHO_2) %>% pmap_dbl(mean)

```

---
## Nest - simplifying your dataframe by making it more complex
```{r}

# Nest all the data by sample
tidy_counts_nest <- tidy_counts_expressed %>% 
  group_by(Sample) %>%
  nest()

#Looking at tibble it is a new datatype that appears simplified
tidy_counts_nest

tidy_counts_nest$data %>% is()

# The data is still there, nested within one of the variables
tidy_counts_nest$data[[1]]

# Map can be used to apply functions across nested dataframes. Here we calculate a linear model. This is also saved in the tibble. 
tidy_counts_nest <- tidy_counts_nest %>% 
  mutate(my_model = map(data, ~lm(CPM ~ TPM, data = .)))

tidy_counts_nest

tidy_counts_nest$my_model %>% is()

tidy_counts_nest$my_model[[1]]

# Tidy also has the ability to "tidy" up outputs from common statisitical packages, using broom.
library(broom)

tidy_counts_nest <- tidy_counts_nest %>% 
  mutate(my_tidy_model = map(my_model, broom::tidy))

tidy_counts_nest

tidy_counts_nest$my_tidy_model[[1]]
```

---
## Unnest - Expand out dataframes
```{r}
#Unnesting to get everything back into a dataframe is very straightforward
tidy_counts_nest %>%
  unnest(my_tidy_model)

#Unnesting can be done sequentially to keep adding to master dataframe
tidy_counts_nest %>%
  unnest(my_tidy_model) %>% 
  unnest(data)

```

---
## CHALLENGE

---
## ANSWER
```{r}


```

# stringr - working with strings

If the data you are working with involves characters from data entry often there will be errors i.e. clinical study metadata or a hand-typed list of genes of interest. Tidying data also means fixing these problems. stringr helps make this easy. 

* Access and manipulate characters
* Deal with whitspace
* Pattern Recognition

Though stringr is pretty comprehensive and covers most of what you will need, there is a sister package called stringi with even more functionality. 

---
## Basic functions to interact with strings
Many overlapping functions with base for combining, subsetting, converting and finding strings

```{r}

brc <- c("Tom", "Ji-Dung", "Matt")

# Extract substrings from a range. Here the 1st to 3rd character
brc %>% str_sub( 1, 3)
brc

# Extract substrings from a range. Here the 2nd to 2nd to last character
brc %>% str_sub( 2, -2)


# Assign values back to substrings. Here the 2nd to 2nd to last character is replaced with X.
str_sub(brc, 2, -2)<-'X'
brc
```

---
## Stripping whitespace
```{r}
brc2 <- c("Tom  ", "  Ji  -Dung", "Matt   ")

#Trim whitespace from strings
brc2 <- str_trim(brc2)
brc2 

#Can add whitespace to strings to get consistent length. Here all are 10 characters
str_pad(brc2, width=10, side='left')

```

---
## Converting strings - Capitalization
```{r}
#Lets reuse our counts tibble. pull from dplyr can be used to grab a tibble column and make it into a vector
tidy_counts_expressed %>% 
  pull(SYMBOL) %>%
  head()

#Here we pull our gene symbols from our tibble into a vector, and then convert them into title style capitalization
tidy_counts_expressed %>% 
  pull(SYMBOL) %>% 
  str_to_title() %>% 
  head()

#String manipulation functions can be used on tibbles using mutate. Here we convert gene symbols to title style capitalization
tidy_counts_expressed %>% 
  mutate(SYMBOL = str_to_title(SYMBOL))

# Here we convert CHR annotation to capitals
tidy_counts_expressed %>% 
  mutate(CHR = str_to_upper(CHR))

```

---
## Finding patterns
```{R}
#Find patterns in different ways
#Detect gives a T/F whether the pattern 'salmon' is present in vector
df1 %>% 
  pull(common_name) %>% 
  str_detect('salmon')

#Subset returns the match if the pattern 'salmon' is present in vector
df1 %>% 
  dplyr::pull(common_name) %>% 
  str_subset('salmon') 

#Ends is similar to detect as it gives gives a T/F whether the pattern 'salmon' is present in vector, but the pattern has to be at the end. 
df1 %>% 
  dplyr::pull(common_name) %>% 
  str_ends('salmon') 

df1 %>% 
  filter(str_ends(common_name,'salmon'))


#Count gives you the total number of times your pattern appears in each chracter in the vector
df1 %>% 
  dplyr::pull(common_name) %>% 
  str_count('salmon')

df1 %>% 
  dplyr::pull(common_name) %>% 
  str_count('o')

#Replace
df1 %>% 
  dplyr::pull(common_name) %>%
  str_replace_all('Steelhead','Steelhead trout' )

df1 %>% 
  mutate(common_name = str_replace_all(common_name,'Steelhead','Steelhead trout' ))

```

---
## CHALLENGE

---
## ANSWER
```{r}


```

# forcats - Handling factors

Factors are a data type that R uses to handle fixed categorical variables that have a known set of possible values. 

Factors are ordered, allowing hierachy to be presevred in relatively simple vectors.

---
## Making a factor - This is all base
```{r}

# Vectors are easy to turn into factors with factor()
tidy_counts_expressed_samples <- tidy_counts_expressed %>% 
  pull(Sample) %>% 
  factor() 

tidy_counts_expressed_samples %>% head(n=10)

# Can also modify the data type of a tibble column with as_facotr, in an approach we have used before.
tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) 

tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>% 
  pull(Sample) %>% head(n=10)

# When you factorize you can use a vector to determine the order
my_levels1<-c('ORTHO_1','ORTHO_2','CD34_1','CD34_2')
tidy_counts_expressed %>% 
  pull(Sample) %>% 
  factor(levels = my_levels1 ) %>% head(n=10)

# When you factorize anything not in the given levels is turned to NA
my_levels2<-c('ORTHO_1','CD34_1')
tidy_counts_expressed %>% 
  pull(Sample) %>% 
  factor(levels = my_levels2 ) %>% head(n=10)

# Its straightforward to grab the levels from the factor
tidy_counts_expressed_samples %>% 
  levels()

```

---
## Why do we factorize? For order:
```{r}

tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>% 
  group_by(Sample) %>% 
  summarize(mean_count=mean(counts)) %>% 
  ggplot(aes(x=Sample, y= mean_count)) + 
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))

```

---
## Changing the order
```{r}

#fct_relevel - reorder manually
tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>%
  mutate(Sample = fct_relevel(Sample, my_levels1)) %>% 
  pull(Sample) %>% head(n=10)

#fct_relevel - reorder manually
tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>%
  mutate(Sample = fct_relevel(Sample, my_levels2)) %>% 
  pull(Sample) %>% head(n=10)


#fct_reorder - reorder based on the data. Here we are ordering based on mean counts for each sample.
tidy_counts_expressed %>%
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>% 
  mutate(Sample = fct_reorder(Sample, counts, mean)) %>% 
  pull(Sample) %>% head(n=10)

```

---
## Now our ordering can be fixed
```{r}

tidy_counts_expressed %>% 
  ungroup() %>% 
  mutate_at(vars(Sample), as_factor) %>%
  mutate(Sample=fct_relevel(Sample, my_levels1)) %>% 
  group_by(Sample) %>% 
  summarize(mean_count=mean(counts)) %>% 
  ggplot(aes(x=Sample, y= mean_count)) + 
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))

```

---
## Other useful things.
```{r}

df1$age_classbylength

# fct_recode - Change levels manually
df1 %>% mutate_at(vars(age_classbylength), as_factor) %>% mutate(age_classbylength=fct_recode(age_classbylength, "mixed juvenile" = "mixed age juvenile")) %>% pull(age_classbylength)

df1 %>% mutate_at(vars(age_classbylength), as_factor) %>% mutate(age_classbylength=fct_recode(age_classbylength, "juvenile" = "mixed age juvenile")) %>% pull(age_classbylength)

# fct_count - Count up the number of each
df1 %>% mutate_at(vars(age_classbylength), as_factor) %>% pull(age_classbylength) %>% fct_count()

# fct_infreq - mask rare factors
df1 %>% mutate_at(vars(age_classbylength), as_factor) %>% mutate(age_classbylength=fct_lump(age_classbylength, n=2)) %>% pull(age_classbylength)
df1 %>% mutate_at(vars(age_classbylength), as_factor) %>% mutate(age_classbylength=fct_lump(age_classbylength, n=2)) %>% pull(age_classbylength) %>% fct_count()

# fct_c - combining factors
A<-factor(c('Tom','Ji-Dung'))
B<-factor('Matt')
fct_c(A,B)
```

---
## CHALLENGE
short/long genes
---
## ANSWER
```{r}


```

# Summary
---
## Tidy packages we have covered

* ~~ggplot2 – making pretty graphs~~ 
* ~~readr – reading data into R~~  
* ~~dplyr – manipulating data~~  
* ~~tibble - working with tibbles~~  
* ~~tidyr – miscellaneous tools for tidying data~~
* ~~purrr - iterating over data~~
* ~~stringr – working with strings~~  
* ~~forcats - working with factors~~  

---
## Tidy beyond this workshop

Hadley Wickham (Chief Scientist at RStudio) is the driving force behind the tidyverse.  

Hadley wrote a paper about why he thinks tidy data is best: www.jstatsoft.org/v59/i10/paper.  

There is a lot of support for all things tidy at: https://www.tidyverse.org/  
(This includes really great cheat sheets for each tool)

---
## Tidy packages to check out:

plyranges: dplyr equivalent for working with ranges i.e. Granges

readxl: This package is very useful when you want to import Excel sheets in R

googledrive: Interact with your googledrive through R

lubridate and hms: Allow managin of calendar and time formats

magrittr: piping tools

broom: helps tidy up standard base function i.e. lm or t.test

tidymodels: A collection of tools for preparing for and validating model functions

---
## Other Good Resources

ggplot  
https://rockefelleruniversity.github.io/Plotting_In_R/

R for Data Science text book  
https://r4ds.had.co.nz/

Data Science with R text book
http://garrettgman.github.io/

Cancer Research UK - Intermediate R course
https://bioinformatics-core-shared-training.github.io/r-intermediate/

# Thanks

*BRC*
IT Pavillion
Tom Carroll: tcarroll@rockefeller.edu
Ji-Dung Luo: jluo@rockefeller.edu
Matt Paul: mpaul@rockefeller.edu

*Data Science Research Group*
Eli:
Doug:
Greg:




